{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wnj5XuwSKaU",
        "outputId": "3e12cfb1-3874-4b77-fdc9-2dc898064824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        }
      ],
      "source": [
        "print(\"hello\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Core Langchain and LangGraph packages\n",
        "# !pip install langchain langgraph langchain_core langchain_community\n",
        "\n",
        "# # Model providers and integrations\n",
        "# !pip install langchain_openai langchain_groq langchain_huggingface\n",
        "\n",
        "# # Utilities and tools\n",
        "# !pip install faiss-cpu python-dotenv tqdm chromadb duckduckgo\n"
      ],
      "metadata": {
        "id": "vvn0_FCEST0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph\n",
        "from langchain_core.messages import HumanMessage\n",
        "from typing_extensions import TypedDict\n",
        "from typing import Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "from typing import TypedDict, List\n",
        "\n",
        "# Define the state\n",
        "from typing import Optional\n",
        "\n",
        "class NewsState(TypedDict):\n",
        "    messages: list\n",
        "    topic: str\n",
        "    raw_news: str\n",
        "    summary: str\n",
        "    article: list\n",
        "    originality_scores: Optional[List[float]]\n",
        "    sentiment: Optional[str]\n",
        "    category: Optional[str]\n",
        "    categories: Optional[List[str]]\n",
        "    entities: List[str]\n",
        "    title: Optional[str]\n",
        "    loop_count: Optional[int]\n",
        "    final_article: Optional[str]\n",
        "    language: Optional[str]\n",
        "    translated_article: Optional[str]\n"
      ],
      "metadata": {
        "id": "3vpiXyqqTNSr",
        "outputId": "94828004-d7a8-41d7-9112-95bfddc624ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langgraph'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c3574696fab4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStateGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHumanMessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTypedDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnnotated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_messages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langgraph'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "TAVILY_API_KEY = userdata.get('TAVILY_API_KEY')\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
        "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY"
      ],
      "metadata": {
        "id": "JfaI8N97TNOe",
        "outputId": "746a4cba-32d6-44ae-ceb1-d6f96ddb3069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SecretNotFoundError",
          "evalue": "Secret GROQ_API_KEY does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3b100f6df9f3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mGROQ_API_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GROQ_API_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mTAVILY_API_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TAVILY_API_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret GROQ_API_KEY does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Node 1: Receive Topic\n",
        "def receive_topic(state: NewsState):\n",
        "    topic = state[\"messages\"][-1].content\n",
        "    return {\"topic\": topic}\n"
      ],
      "metadata": {
        "id": "wDZVQTWsTNL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tool = TavilySearchResults(\n",
        "    max_results=5,\n",
        "    search_depth=\"advanced\",\n",
        "    include_raw_content=True\n",
        ")\n",
        "\n",
        "# # Directly call the tool\n",
        "# def fetch_news(state: NewsState):\n",
        "#     query = state[\"topic\"]\n",
        "#     # The result of tool.invoke is a list of dictionaries\n",
        "#     search_results_list = tool.invoke({\"query\": query})\n",
        "#     print(\"Raw Tavily Response:\", search_results_list)\n",
        "\n",
        "#     processed_news = []\n",
        "#     # Iterate directly over the list returned by the tool\n",
        "#     for item in search_results_list:\n",
        "#         processed_news.append({\n",
        "#             \"title\": item.get(\"title\", \"No title\"),\n",
        "#             \"content\": item.get(\"content\", \"\"),\n",
        "#             \"url\": item.get(\"url\", \"\")\n",
        "#         })\n",
        "\n",
        "#     # The __artifacts should store the raw list, not an item from the loop\n",
        "#     return {\n",
        "#         \"raw_news\": processed_news,\n",
        "#         \"__artifacts\": {\n",
        "#             \"search_query\": state[\"topic\"],\n",
        "#             \"search_results\": search_results_list # Store the full list here\n",
        "#         }\n",
        "#     }\n",
        "\n",
        "\n",
        "# from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "# tool = TavilySearchResults(\n",
        "#     max_results=5,\n",
        "#     search_depth=\"advanced\",\n",
        "#     include_raw_content=True\n",
        "# )\n",
        "\n",
        "def fetch_news(state: NewsState) -> dict:\n",
        "    query = state[\"topic\"]\n",
        "    loop_count = state.get(\"loop_count\", 0)\n",
        "\n",
        "    # The result of tool.invoke is a list of dictionaries\n",
        "    search_results_list = tool.invoke({\"query\": query})\n",
        "    print(\"Raw Tavily Response:\", search_results_list)\n",
        "\n",
        "    processed_news = []\n",
        "    article_texts = []\n",
        "\n",
        "    for item in search_results_list:\n",
        "        content = item.get(\"content\", \"\")\n",
        "        processed_news.append({\n",
        "            \"title\": item.get(\"title\", \"No title\"),\n",
        "            \"content\": content,\n",
        "            \"url\": item.get(\"url\", \"\")\n",
        "        })\n",
        "        article_texts.append(content)\n",
        "\n",
        "    return {\n",
        "        \"raw_news\": processed_news,\n",
        "        \"article\": article_texts,\n",
        "        \"loop_count\": loop_count + 1,\n",
        "        \"__artifacts\": {\n",
        "            \"search_query\": query,\n",
        "            \"search_results\": search_results_list\n",
        "        }\n",
        "    }\n"
      ],
      "metadata": {
        "id": "5Gsd1bLyUMsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 2. Filter Node\n",
        "def filter_irrelevant(state: NewsState) -> dict:\n",
        "    raw = state.get(\"raw_news\", [])\n",
        "\n",
        "    # Filter out items with empty or very short content\n",
        "    filtered = [\n",
        "        item for item in raw\n",
        "        if item.get(\"content\") and len(item[\"content\"]) > 50\n",
        "    ]\n",
        "\n",
        "    print(f\"Filtered: {len(filtered)} / {len(raw)}\")\n",
        "\n",
        "    return {\"raw_news\": filtered}"
      ],
      "metadata": {
        "id": "yKjp_eLYSeGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # === Router for Filter Node ===\n",
        "# def route_filter(state: NewsState) -> str:\n",
        "#     news_count = len(state.get(\"raw_news\", []))\n",
        "#     if news_count < 5:\n",
        "#         print(\"News count < 5, looping back to search.\")\n",
        "#         return \"FetchNews\"\n",
        "#     return \"SummarizeNews\"\n",
        "def route_filter(state: NewsState) -> str:\n",
        "    if len(state.get(\"raw_news\", [])) < 5:\n",
        "        print(\"Routing back to FetchNews\")\n",
        "        return False\n",
        "    print(\"Routing to SummarizeNews\")\n",
        "    return True\n"
      ],
      "metadata": {
        "id": "OcqospDASpDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Originality\n",
        "def check_originality(state: NewsState) -> dict:\n",
        "    article = state.get('article', \"\")\n",
        "    prompt = f\"Rate the originality of this article from 1 to 10:\\n{article}\"\n",
        "    score = llm.invoke(prompt).content.strip()\n",
        "    print(\"Score from LLM:\", score)\n",
        "    return {\"originality_scores\": [score]}\n",
        "\n",
        "\n",
        "\n",
        "# def originality_checker(state: NewsState) -> str:\n",
        "#     scores = state.get(\"originality_scores\", [])\n",
        "#     print(\"Originality scores:\", scores)\n",
        "\n",
        "#     valid_scores = []\n",
        "#     for score in scores:\n",
        "#         try:\n",
        "#             valid_scores.append(float(score))\n",
        "#         except (ValueError, TypeError):\n",
        "#             continue\n",
        "\n",
        "#     if valid_scores and max(valid_scores) > 5.0:\n",
        "#         print(\"Routing to: SummarizeNews\")\n",
        "#         return True\n",
        "\n",
        "#     print(\"Routing to: FetchNews\")\n",
        "#     return False\n",
        "\n",
        "def originality_checker(state: NewsState) -> str:\n",
        "    scores = state.get(\"originality_scores\", [])\n",
        "    loop_count = state.get(\"loop_count\", 0)\n",
        "    print(\"Originality scores:\", scores, \"Loop:\", loop_count)\n",
        "\n",
        "    valid_scores = []\n",
        "    for score in scores:\n",
        "        try:\n",
        "            valid_scores.append(float(score))\n",
        "        except (ValueError, TypeError):\n",
        "            continue\n",
        "\n",
        "    # Stop looping after 3 tries\n",
        "    if loop_count >= 3:\n",
        "        print(\"Too many loops, proceeding to summarize anyway.\")\n",
        "        return True\n",
        "\n",
        "    if valid_scores and max(valid_scores) > 5.0:\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n"
      ],
      "metadata": {
        "id": "XGdQuFdhXueC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Node 3: Summarize News\n",
        "from langchain_groq import ChatGroq\n",
        "llm = ChatGroq(\n",
        "    model=\"DeepSeek-R1-Distill-Llama-70b\",\n",
        "    temperature=0.7,\n",
        "    streaming=True,\n",
        "    verbose=True\n",
        ")\n",
        "def summarize_news(state: NewsState):\n",
        "    prompt = f\"Summarize this news:\\n{state['raw_news']}\"\n",
        "    summary = llm.invoke(prompt).content.strip()\n",
        "    return {\"summary\": summary}\n"
      ],
      "metadata": {
        "id": "yNTwbBxnUMoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze Sentiment\n",
        "def analyze_sentiment(state: NewsState):\n",
        "    article = state.get('article')\n",
        "    if article:\n",
        "        prompt = f\"Classify the sentiment of this news article as Positive, Negative, or Neutral:\\n{article}\"\n",
        "        sentiment = llm.invoke(prompt).content.strip()\n",
        "        return {\"sentiment\": sentiment}\n",
        "    return {\"sentiment\": \"No article provided\"}"
      ],
      "metadata": {
        "id": "xVdpedAZhWwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorize Article\n",
        "def categorize_article(state: NewsState):\n",
        "    summary = state.get('summary')\n",
        "    if isinstance(summary, list):\n",
        "        categories = []\n",
        "        for s in summary:\n",
        "            prompt = f\"What is the category of this summary? Choose from: Politics, Tech, Sports, Economy, Health, Entertainment.\\n{s}\"\n",
        "            category = llm.invoke(prompt).content.strip()\n",
        "            categories.append(category)\n",
        "        print(\"Categories:\", categories)\n",
        "        return {\"categories\": categories}\n",
        "    elif isinstance(summary, str):\n",
        "        prompt = f\"What is the category of this summary? Choose from: Politics, Tech, Sports, Economy, Health, Entertainment.\\n{summary}\"\n",
        "        category = llm.invoke(prompt).content.strip()\n",
        "        print(\"Category:\", category)\n",
        "        return {\"category\": category}\n",
        "    return {\"category\": \"No summary provided\"}"
      ],
      "metadata": {
        "id": "2q3jeNaAhWuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract Entities\n",
        "def extract_entities(state: NewsState):\n",
        "    article = state.get(\"article\")\n",
        "    if article:\n",
        "        prompt = f\"Extract all named entities (people, places, organizations) from this article:\\n{article}\"\n",
        "        response = llm.invoke(prompt).content.strip()\n",
        "        print(\"Entities:\", response)\n",
        "        return {\"entities\": response}\n",
        "\n",
        "    return {\"entities\": \"No article available for entity extraction\"}"
      ],
      "metadata": {
        "id": "Us2zhv_GiqZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Title\n",
        "def generate_title(state: NewsState):\n",
        "    summary = state.get(\"summary\")\n",
        "    prompt = f\"Generate a catchy headline for this article:\\n{summary}\"\n",
        "    title = llm.invoke(prompt).content.strip()\n",
        "    print(\"Generated Title:\", title)\n",
        "    return {\"title\": title}"
      ],
      "metadata": {
        "id": "FTDPo40aiEkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Article\n",
        "def generate_article(state: NewsState):\n",
        "    prompt = f\"Write a news article based on this summary:\\n{state['summary']}\"\n",
        "    article = llm.invoke(prompt).content.strip()\n",
        "    print(\"Generated Article:\", article)\n",
        "    return {\n",
        "        \"article\": article,\n",
        "        # Use HumanMessage instead of raw dict\n",
        "        \"messages\": [HumanMessage(content=article)]\n",
        "    }"
      ],
      "metadata": {
        "id": "as14CyvZi1st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_and_check_article(state: NewsState):\n",
        "    title = state.get(\"title\", \"\")\n",
        "    article = state.get(\"article\", \"\")\n",
        "\n",
        "    # Convert article list to a string if needed\n",
        "    if isinstance(article, list):\n",
        "        article = \"\\n\\n\".join(article)\n",
        "\n",
        "    full_text = f\"Title: {title}\\n\\n{article}\"\n",
        "\n",
        "    prompt = f\"\"\"Please proofread and correct any spelling or grammar mistakes in the following article. Keep the structure and tone intact.\n",
        "\n",
        "              --- ARTICLE START ---\n",
        "\n",
        "              {full_text}\n",
        "\n",
        "              --- ARTICLE END ---\n",
        "\n",
        "              Return the cleaned-up article below:\"\"\"\n",
        "\n",
        "    final_article = llm.invoke(prompt).content.strip()\n",
        "\n",
        "    return {\"final_article\": final_article}\n"
      ],
      "metadata": {
        "id": "7G7l93BJk68J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import HumanInputRun\n",
        "\n",
        "# This tool allows waiting for human input\n",
        "human_input = HumanInputRun()\n",
        "\n",
        "def get_user_language_choice(state: NewsState):\n",
        "    language = human_input.run(\"Enter the language to translate the article into:\")\n",
        "    return {\"language\": language}\n"
      ],
      "metadata": {
        "id": "FVCGelZunN4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_article(state: NewsState):\n",
        "    language = state.get(\"language\", \"English\")\n",
        "    final_article = state.get(\"final_article\", \"\")\n",
        "    if language != None:\n",
        "      prompt = f\"\"\"Translate the following article into {language}:\n",
        "\n",
        "  --- ARTICLE START ---\n",
        "  {final_article}\n",
        "  --- ARTICLE END ---\n",
        "\n",
        "  Return the full translation below:\"\"\"\n",
        "\n",
        "      translated = llm.invoke(prompt).content.strip()\n",
        "      return {\"translated_article\": translated}\n",
        "    return {\"translated_article\": final_article}\n"
      ],
      "metadata": {
        "id": "mqiEdhkenIEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder = StateGraph(NewsState)\n",
        "\n",
        "# Add nodes\n",
        "graph_builder.add_node(\"ReceiveTopic\", receive_topic)\n",
        "graph_builder.add_node(\"FetchNews\", fetch_news)\n",
        "graph_builder.add_node(\"FilterNews\", filter_irrelevant)\n",
        "graph_builder.add_node(\"CheckOriginality\", check_originality)\n",
        "graph_builder.add_node(\"SummarizeNews\", summarize_news)\n",
        "graph_builder.add_node(\"AnalyzeSentiment\", analyze_sentiment)\n",
        "graph_builder.add_node(\"CategorizeArticle\", categorize_article)\n",
        "graph_builder.add_node(\"ExtractEntities\", extract_entities)\n",
        "graph_builder.add_node(\"GenerateTitle\", generate_title)\n",
        "graph_builder.add_node(\"GenerateArticle\", generate_article)\n",
        "graph_builder.add_node(\"CompileAndCheckArticle\", compile_and_check_article)\n",
        "graph_builder.add_node(\"GetUserLanguageChoice\", get_user_language_choice)\n",
        "graph_builder.add_node(\"TranslateArticle\", translate_article)\n",
        "\n",
        "\n",
        "# Set up edges (same as before)\n",
        "graph_builder.set_entry_point(\"ReceiveTopic\")\n",
        "graph_builder.add_edge(\"ReceiveTopic\", \"FetchNews\")\n",
        "graph_builder.add_edge(\"FetchNews\", \"FilterNews\")\n",
        "graph_builder.add_conditional_edges(\"FilterNews\", route_filter, {True: \"CheckOriginality\", False: \"FetchNews\"})\n",
        "# graph_builder.add_edge(\"CheckOriginality\", \"SummarizeNews\")\n",
        "graph_builder.add_conditional_edges(\"CheckOriginality\", originality_checker, {True: \"SummarizeNews\", False: \"FetchNews\"})\n",
        "graph_builder.add_edge(\"SummarizeNews\", \"AnalyzeSentiment\")\n",
        "graph_builder.add_edge(\"SummarizeNews\", \"CategorizeArticle\")\n",
        "graph_builder.add_edge(\"SummarizeNews\", \"ExtractEntities\")\n",
        "graph_builder.add_edge(\"SummarizeNews\", \"GenerateTitle\")\n",
        "graph_builder.add_edge(\"AnalyzeSentiment\", \"GenerateArticle\")\n",
        "graph_builder.add_edge(\"CategorizeArticle\", \"GenerateArticle\")\n",
        "graph_builder.add_edge(\"ExtractEntities\", \"GenerateArticle\")\n",
        "graph_builder.add_edge(\"GenerateTitle\", \"CompileAndCheckArticle\")\n",
        "graph_builder.add_edge(\"GenerateArticle\", \"CompileAndCheckArticle\")\n",
        "graph_builder.add_edge(\"CompileAndCheckArticle\", \"GetUserLanguageChoice\")\n",
        "graph_builder.add_edge(\"GetUserLanguageChoice\", \"TranslateArticle\")\n",
        "graph_builder.set_finish_point(\"TranslateArticle\")\n",
        "\n",
        "graph = graph_builder.compile()\n",
        "# Example invocation\n",
        "inputs = {\"messages\": [HumanMessage(content=\"AI in india\")]}\n",
        "result = graph.invoke(inputs)\n",
        "\n"
      ],
      "metadata": {
        "id": "yUf1eFAUUMqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['final_article'])"
      ],
      "metadata": {
        "id": "ho-IGDjPUMmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pyppeteer\n",
        "# # You might also need to install a browser executable if pyppeteer hasn't done it.\n",
        "# # Run this command in your terminal if pyppeteer can't find a browser:\n",
        "# # pyppeteer-install"
      ],
      "metadata": {
        "id": "Zowqtye7aK0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "# display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "\n",
        "# # Import CurveStyle and MermaidDrawMethod from langgraph.graph.mermaid\n",
        "# from langgraph.graph.mermaid import CurveStyle, MermaidDrawMethod, NodeStyles\n",
        "from langchain_core.runnables.graph_mermaid import draw_mermaid_png\n",
        "\n",
        "display(\n",
        "    Image(\n",
        "        graph.get_graph().draw_mermaid_png(\n",
        "        )\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "BMrmvSx4Z6mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tMRFqzQbZ6ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AQN42TFWZ6it"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}